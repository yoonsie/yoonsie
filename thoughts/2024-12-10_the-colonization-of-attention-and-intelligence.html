<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="robots" content="noindex, nofollow">
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Yoonsie Kim | Library | the colonization of attention and intelligence</title>
        <!-- Stylesheet -->
        <link rel="stylesheet" type="text/css" href="../css/styles.css" media="screen"/>
        <!-- Favicon-->
        <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
        <!-- Font Awesome Kit, which isn't working for some reason -->
        <script src="https://kit.fontawesome.com/abb64863b6.js" crossorigin="anonymous"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-7BLNT4L46D"></script>
    </head>
    <body id="page-top">
      <!-- Navigation bar / menu -->
      <div class="nav">
        <div class="nav-item"><a href="../index.html">about</a></div>
        <div class="nav-item"><a href="../play.html">play</a></div>
        <div class="nav-item"><a id="current">thoughts</a></div>
        <div class="nav-item"><a href="../library.html">library</a></div>
      </div>
      <!-- Library -->
      <div class="main">
        <!-- Breadcrumbs -->
        <p class="center"><span><a href="../thoughts.html">Ruminations and remnants</a></span> / <span class="strong"></span></p>
        <p class="blog">
          I recently watched a clip of <a href="https://youtu.be/SUTbnjIHfkg?si=sOlQTxCCmcmj7rX8&t=76" target="_blank">Bo Burnham's comments <i class="fa fa-external-link fa-2xs" aria-hidden="true"></i></a> about social media, which can be applied to the attention economy at large.
          <blockquote cite="https://youtu.be/SUTbnjIHfkg?si=sOlQTxCCmcmj7rX8&t=76">Because these companies went public they have to grow, they cannot stay stagnant. It is unprofitable. We colonized the entire Earth. There was no other place for business and capitalism to expand into, and then they realized [they can colonize] human attention. They are now trying to colonize every minute of your life. Every single free moment you have is a moment you could be looking at your phone and they could be gathering information to target ads at you. </blockquote>
        </p>
        <p class="blog">
          Burnham provides an interesting perspective. We are bombarded by companies that compete for our attention to either (a) sell us stuff or (b) sell our data to a company that can sell us stuff. Per Burnham, businesses have gone to colonize resources in this sequence:
        </p>
          <ul class="blog">
            <li>Land</li>
            <li>Attention</li>
          </ul>
        <p>But, I'd like to re-scope what was and what will be colonized:
        </p>
        <ul class="blog">
          <li>Environmental Resources: Land, Water, Seeds/Spices, Animals, etc.</li>
          <li>Human Resources: Labor/Time, Trade Networks, Healthcare (which I will not get into in this post), <span class="strong">Attention</span>, and <span class="strong">Intelligence</span></li>
        </ul>
        <p>
          The privileged have gone from colonizing environmental to human resources centuries ago. Today though, they are expanding upon exploiting just our labor and time to our attention--as Burnham said--and with the advent of AI, our intelligence. AI is not created via spontaneous generation. Artificial Intelligence is an artifice—id est, a 'clever trick' or 'stratagem' sourced from and simulating that of human intelligence. AI programs are trained on data of or by humans. Much of the collective knowledge humans have documented or shared is being fed to AI programs without prior communication let alone consent. Companies exploit the contributions of others for profit. Most insiduously, they will sell products that harm those same individuals. Though AI technology is new, its model of exploitation is not. A similarly hard-to-resist and high-demand commodity which followed this model was sugar. Enslaved people were forced to cultivate sugar, which was then sold back to their communities, creating a cycle of economic exploitation<sup><a href="https://www.nytimes.com/interactive/2019/08/14/magazine/sugar-slave-trade-slavery.html" target="_blank">1</a></sup>. As a result of both oppression and resourcefulness, sugar became a cornerstone of their diet, which has led to modern repercussions among these very communities. For example, the likelihood of dietary diseases such as diabetes is significantly higher among the affected diaspora<sup><a href="https://thedo.osteopathic.org/columns/food-from-the-soul-a-history-of-african-american-culture-and-nutrition/" target="_blank">2</a></sup>.
        </p>
        <p>
          While harvesting data for AI falls categorically outside of slavery, it shares the lack of power of consent of a group of individuals. In both cases, the product is extracted by the more privileged from the less privileged—whether through labor or data—then re-commodified to those who contributed to its very creation. This process is evident in how AI systems depend on user data, yet these users receive no direct compensation for their contributions. This familiar cycle of reselling something potentially harmful back to its contributors is also mirrored in the growing concerns about the overreliance on AI tools. Then, if AI is the sugar of today, what will be the diabetes of tomorrow?
        </p>
        <footer>&copy; <span id="copyright-year"></span> Yoonsie Kim. All rights reserved.</footer>
        <script>
          document.getElementById('copyright-year').textContent = new Date().getFullYear();
        </script>
    </body>
</html>
